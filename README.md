## World-University-Ranking-Analysis
OBJECTIVES
To perform an initial data and exploratory analysis of THE World University Ranking data and to extract a conclusions of that data.

Analyze the data to answer questions about the top universities, top countries with the best universities,what are the factors in rankings of the top universities).

Analyze the data to discover if there is a relationship between the spending in the education and the number of top universities in the world).

Create a storyboard with the analisys and conclutions on Tableau.).

TOOLS
Language: Python

Libraries: Pandas, Numpy, Seaborn, Matplotlib, and Scipy

Software: Jupyter Notebooks, Excel, Tableau

NEEDED SKILLS
Data Consistency Checks and Data Wrangling:removing duplicates, found and resolving missing values, addressing mixed or incorrect data types.

Combining & Exporting Data: selecting and preparing data for merging, and exporting final merge as a pkl file.

Derived new variables: grouping data by user, order, and department to allow exploration and analysis at each level; using aggregated data to create flags about user ordering habits (such as ‘new customer’, ‘loyal customer’, etc.) and demographic info (such as ‘with babies’ or ‘pet owner’); confirming the new data created via crosstabs and value counts.

Exploratory analysis: exploring basic descriptive statistics (max/min, quartiles, mean, standard deviation) for each variable as well as using histograms, scatterplots, and bar and line charts to explore the distributions of data.

Visualizing data: using Matplotlib and Seaborn to create histograms, line charts, pie charts, and bar charts (vertical/horizontal), stacked, and 100% stacked, Spatial visualisation in Python, Correlation Matrices and Heat Maps, Scatterplots, Pair plots, Categorical Plots).

Perform Supervised Machine Learning: Regression and Unsupervised Machine Learning: Clustering

Sourcing & Analyzing Time Series Data 

Creating Data Dashboards with Tableau

Reporting results: providing an dashboard on Tableau presenting all the condacted analisys and conclusions as well as documenting the data population flow, consistency checks, data wrangling, and column derivations.
